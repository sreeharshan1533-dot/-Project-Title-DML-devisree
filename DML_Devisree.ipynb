{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLx8CG7Posow",
        "outputId": "e58e6355-b415-40e3-f3d9-daeacd375645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive OLS ATE: 2.0212737059762373\n",
            "PSM ATE: 1.8004320386529626\n",
            "DML ATE: 1.9979549220259805\n",
            "True CATE (first 5): [2.5658463  0.97625664 1.76944718 1.94412803 3.57853692]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "import statsmodels.api as sm\n",
        "np.random.seed(42)\n",
        "n = 2000\n",
        "p = 5\n",
        "\n",
        "X = np.random.normal(0, 1, (n, p))\n",
        "\n",
        "# True heterogeneous treatment effect\n",
        "tau = 2 + X[:, 0] - 0.5 * X[:, 1]\n",
        "\n",
        "# Propensity score (non-random assignment)\n",
        "logit_p = 0.5 * X[:, 0] - 0.25 * X[:, 2]\n",
        "p_score = 1 / (1 + np.exp(-logit_p))\n",
        "D = np.random.binomial(1, p_score)\n",
        "\n",
        "# Outcome\n",
        "Y = tau * D + X[:, 0] + 0.5 * X[:, 1] + np.random.normal(0, 1, n)\n",
        "X_ols = sm.add_constant(np.column_stack([D, X]))\n",
        "ols_model = sm.OLS(Y, X_ols).fit()\n",
        "print(\"Naive OLS ATE:\", ols_model.params[1])\n",
        "ps_model = GradientBoostingClassifier()\n",
        "ps_model.fit(X, D)\n",
        "ps_hat = ps_model.predict_proba(X)[:, 1]\n",
        "\n",
        "treated = np.where(D == 1)[0]\n",
        "control = np.where(D == 0)[0]\n",
        "\n",
        "nn = NearestNeighbors(n_neighbors=1)\n",
        "nn.fit(ps_hat[control].reshape(-1, 1))\n",
        "\n",
        "matches = nn.kneighbors(ps_hat[treated].reshape(-1, 1), return_distance=False)\n",
        "\n",
        "psm_effect = np.mean(Y[treated] - Y[control][matches.flatten()])\n",
        "print(\"PSM ATE:\", psm_effect)\n",
        "K = 2\n",
        "kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "Y_res = np.zeros(n)\n",
        "D_res = np.zeros(n)\n",
        "\n",
        "for train_idx, test_idx in kf.split(X):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
        "    D_train, D_test = D[train_idx], D[test_idx]\n",
        "\n",
        "    # Outcome model\n",
        "    y_model = GradientBoostingRegressor()\n",
        "    y_model.fit(X_train, Y_train)\n",
        "    m_hat = y_model.predict(X_test)\n",
        "\n",
        "    # Treatment model\n",
        "    d_model = GradientBoostingClassifier()\n",
        "    d_model.fit(X_train, D_train)\n",
        "    p_hat = d_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    Y_res[test_idx] = Y_test - m_hat\n",
        "    D_res[test_idx] = D_test - p_hat\n",
        "dml_model = LinearRegression()\n",
        "dml_model.fit(D_res.reshape(-1, 1), Y_res)\n",
        "\n",
        "print(\"DML ATE:\", dml_model.coef_[0])\n",
        "cate_hat = tau  # true CATE for comparison\n",
        "\n",
        "print(\"True CATE (first 5):\", cate_hat[:5])\n"
      ]
    }
  ]
}